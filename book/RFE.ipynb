{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Selección de Variables con Regresión Lineal\n",
    "\n",
    "¡Hola! En este notebook, vamos a explorar un concepto fundamental en el Machine Learning: la **selección de variables** (o *feature selection*).\n",
    "\n",
    "## ¿Por qué es importante la Selección de Variables?\n",
    "\n",
    "Cuando construimos un modelo, a menudo tenemos acceso a una gran cantidad de variables o características. Sin embargo, no todas son útiles. Algunas pueden ser ruidosas o irrelevantes. La selección de variables nos ayuda a:\n",
    "\n",
    "1.  **Mejorar el rendimiento del modelo**: Eliminar variables irrelevantes puede reducir el ruido y permitir que el modelo se enfoque en las señales importantes.\n",
    "2.  **Reducir el sobreajuste (Overfitting)**: Un modelo más simple, con menos variables, es menos propenso a memorizar los datos de entrenamiento y generaliza mejor a datos nuevos.\n",
    "3.  **Aumentar la interpretabilidad**: Es mucho más fácil entender un modelo que depende de 5 variables que uno que depende de 50.\n",
    "4.  **Reducir el costo computacional**: Entrenar un modelo con menos variables es más rápido y consume menos recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Importar las librerías necesarias\n",
    "\n",
    "Comenzaremos importando las herramientas que vamos a utilizar de `numpy` para operaciones numéricas y `sklearn` para generar datos, crear el modelo y realizar la selección de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Crear un conjunto de datos de ejemplo\n",
    "\n",
    "Para hacer este ejercicio más didáctico, vamos a crear nuestro propio conjunto de datos usando `make_regression`. La ventaja es que podemos controlar exactamente cuántas variables son realmente útiles.\n",
    "\n",
    "Crearemos un dataset con:\n",
    "- **20 variables en total** (`n_features=20`).\n",
    "- De las cuales, **solo 5 serán informativas** (`n_informative=5`).\n",
    "\n",
    "El objetivo será ver si nuestro método de selección de variables puede identificar correctamente estas 5 variables importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el dataset sintético\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=5, noise=20, random_state=42)\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dimensiones de los datos de entrenamiento (X_train): {X_train.shape}\")\n",
    "print(f\"Dimensiones de los datos de prueba (X_test): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Modelo Base - usamos TODAS las variables\n",
    "\n",
    "Primero, entrenaremos un modelo de Regresión Lineal utilizando las 20 variables. Esto nos servirá como punto de comparación (baseline) para ver si la selección de variables mejora o no nuestro resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos y entrenamos el modelo de Regresión Lineal\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones en el conjunto de prueba\n",
    "y_pred_full = model_full.predict(X_test)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo\n",
    "mse_full = mean_squared_error(y_test, y_pred_full)\n",
    "r2_full = r2_score(y_test, y_pred_full)\n",
    "\n",
    "print(\"--- Resultados del Modelo con Todas las Variables ---\")\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse_full:.2f}\")\n",
    "print(f\"Coeficiente de Determinación (R²): {r2_full:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Aplicar Selección de Variables\n",
    "\n",
    "Ahora, aplicaremos una técnica llamada **Eliminación Recursiva de Características (Recursive Feature Elimination - RFE)**.\n",
    "\n",
    "**¿Cómo funciona RFE?**\n",
    "1.  Entrena un modelo (en nuestro caso, Regresión Lineal) con todas las variables.\n",
    "2.  Calcula la importancia de cada variable (para la regresión lineal, esto se basa en los coeficientes).\n",
    "3.  Elimina la variable menos importante.\n",
    "4.  Repite el proceso hasta que quede el número de variables que le hemos especificado.\n",
    "\n",
    "Le pediremos a RFE que seleccione las 5 mejores variables, ya que sabemos que ese es el número de variables informativas que creamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo que usará RFE para evaluar las variables\n",
    "estimator = LinearRegression()\n",
    "\n",
    "# Inicializamos RFE para seleccionar las 5 mejores variables\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "\n",
    "# Aplicamos RFE sobre los datos de entrenamiento\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos las máscaras de las variables seleccionadas\n",
    "selected_features_mask = selector.support_\n",
    "\n",
    "print(f\"Máscara de variables seleccionadas: \\n{selected_features_mask}\")\n",
    "\n",
    "# Veamos los índices de las variables que RFE ha elegido\n",
    "selected_indices = np.where(selected_features_mask)[0]\n",
    "print(f\"\\nÍndices de las variables seleccionadas: \\n{selected_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Modelo Mejorado - Usando solo variables seleccionadas\n",
    "\n",
    "Ahora que RFE ha identificado las variables más importantes, vamos a:\n",
    "1.  Filtrar nuestros conjuntos de datos `X_train` y `X_test` para quedarnos solo con esas columnas.\n",
    "2.  Entrenar un nuevo modelo de Regresión Lineal con este subconjunto de datos.\n",
    "3.  Evaluar su rendimiento y compararlo con el modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos los datos para quedarnos solo con las variables seleccionadas\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "print(f\"Nuevas dimensiones de X_train_selected: {X_train_selected.shape}\")\n",
    "\n",
    "# Inicializamos y entrenamos el nuevo modelo\n",
    "model_selected = LinearRegression()\n",
    "model_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Hacemos predicciones con el nuevo modelo\n",
    "y_pred_selected = model_selected.predict(X_test_selected)\n",
    "\n",
    "# Evaluamos el rendimiento\n",
    "mse_selected = mean_squared_error(y_test, y_pred_selected)\n",
    "r2_selected = r2_score(y_test, y_pred_selected)\n",
    "\n",
    "print(\"\\n--- Resultados del Modelo con Variables Seleccionadas ---\")\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse_selected:.2f}\")\n",
    "print(f\"Coeficiente de Determinación (R²): {r2_selected:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Conclusiones y Comparación\n",
    "\n",
    "Finalmente, comparemos los resultados de ambos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- COMPARACIÓN DE MODELOS ---\\n\")\n",
    "print(f\"Modelo con TODAS las variables (20):\")\n",
    "print(f\"  - R²: {r2_full:.4f}\")\n",
    "print(f\"  - MSE: {mse_full:.2f}\\n\")\n",
    "\n",
    "print(f\"Modelo con variables SELECCIONADAS (5):\")\n",
    "print(f\"  - R²: {r2_selected:.4f}\")\n",
    "print(f\"  - MSE: {mse_selected:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los resultados\n",
    "\n",
    "Observando la comparación, deberíamos notar que:\n",
    "\n",
    "- El **Coeficiente de Determinación (R²)** es muy similar en ambos modelos. Esto significa que nuestro modelo más simple (con solo 5 variables) explica la varianza de los datos casi tan bien como el modelo complejo (con 20 variables).\n",
    "- El **Error Cuadrático Medio (MSE)** también es muy parecido. A veces, incluso puede ser ligeramente menor en el modelo con variables seleccionadas, lo que indicaría que hemos eliminado ruido.\n",
    "\n",
    "**En resumen, hemos logrado un modelo:**\n",
    "\n",
    "✅ **Igual de preciso** (o casi).\n",
    "✅ **Mucho más simple** (4 veces menos variables).\n",
    "✅ **Más interpretable** y **eficiente**.\n",
    "\n",
    "Este es el poder de la selección de variables. Es un paso crucial para construir modelos de Machine Learning robustos y eficientes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
